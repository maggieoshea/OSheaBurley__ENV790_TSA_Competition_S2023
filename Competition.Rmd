---
title: "Wrangling Competition Data"
author: "Katherine Burley & Maggie O'Shea"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

## Notes from Maggie
  - I was thinking it may be good to have a spot at the top of the RMD to say what we've been up to, questions, etc. so here it is! Happy to use another format too, but just thought this is an easy place to find notes to each other when we open the file 
  - The final assignment requires that we write about our models a little bit (I think? The competition instructions seem to suggest there is some writing component)
      - Because of this, I was thinking maybe after we run a model we could include a few sentences of our interpretation of it, that way when it comes time to submit we won't have to go back through and remember what we thought about it. I started to do that just by reporting the RMSE/MAPE and if they are smaller/larger than others which feels like enough, but open to suggestions if you think we should put more. 


## Load Libraries

```{r message = FALSE, warning=FALSE}
library(tidyverse)
library(readxl)
library(lubridate)
library(ggplot2)
library(forecast)  
#library(Kendall)
library(tseries)
#library(outliers)
library(tidyverse)
library(smooth)
library(kableExtra)
```

## Import the Dataset

#### Instructions:

In the folder `/Competition/Data` you will find three datasets one with hourly demand, one with hourly temperature and another with relative humidity from January 2005 to December 2010.
Your goal is to forecast **daily** demand for the month of January 2011 based on this historical data. You may or may not use the temperature and relative humidity in your models. The temperature and humidity measurement are from stations close to the household meter data you have.


```{r}
hourly_demand <- read_excel("./Data/load.xlsx")
hourly_temp<- read_excel("./Data/temperature.xlsx")
hourly_humidity<- read_excel("./Data/relative_humidity.xlsx")
```


## Wrangle/Process the Dataset

#### Instructions: 

You will need to transform hourly data into daily data. See the Rmd file from Lesson 11 for instructions on how to aggregate your dataset using pipes.

Note that I provided hourly data. You should take the **average** of the 24 hours to obtain the daily load.


```{r}
daily_demand <- hourly_demand%>%
  group_by(date, meter_id)%>%
  summarize(
    daily_average = (h1+h2+h3+h4+h5+h6+h7+h8+h9+h10+h11+h12+
                       h13+h14+h15+h16+h17+h18+h19+h20+h21+h22+h23+h24)/24
  )

daily_temp <- hourly_temp%>%
  group_by(date)%>%
  summarize(avg_t_ws1 = mean(t_ws1),
            avg_t_ws2 = mean(t_ws2),
            avg_t_ws3 = mean(t_ws3),
            avg_t_ws4 = mean(t_ws4),
            avg_t_ws5 = mean(t_ws5),
            avg_t_ws6 = mean(t_ws6),
            avg_t_ws7 = mean(t_ws7),
            avg_t_ws8 = mean(t_ws8),
            avg_t_ws9 = mean(t_ws9),
            avg_t_ws10 = mean(t_ws10),
            avg_t_ws11 = mean(t_ws11),
            avg_t_ws12 = mean(t_ws12),
            avg_t_ws13 = mean(t_ws13),
            avg_t_ws13 = mean(t_ws13),
            avg_t_ws14 = mean(t_ws14),
            avg_t_ws15 = mean(t_ws15),
            avg_t_ws16 = mean(t_ws16),
            avg_t_ws17 = mean(t_ws17),
            avg_t_ws18 = mean(t_ws18),
            avg_t_ws19 = mean(t_ws19),
            avg_t_ws20 = mean(t_ws20),
            avg_t_ws21 = mean(t_ws21),
            avg_t_ws22 = mean(t_ws22),
            avg_t_ws23 = mean(t_ws23),
            avg_t_ws24 = mean(t_ws24),
            avg_t_ws25 = mean(t_ws25),
            avg_t_ws26 = mean(t_ws26),
            avg_t_ws27 = mean(t_ws27),
            avg_t_ws28 = mean(t_ws28))

daily_humidity <- humidity%>%
  pivot_longer(cols = -c(hr, date), names_to = "rh", values_to = "humidity")%>%
  group_by(date, rh)%>%
  summarize(avg_humidity = mean(humidity))%>%
  pivot_wider(values_from = "avg_humidity", names_from = "rh")
  
```


## Create a Time Series Object

#### Instructions: 

After you process your dataset use the `msts()` function to create a time series object. You need to use `msts()` instead of `ts()` because your daily data will have more than one seasonal component.

```{r}
# Look at data
ggplot(daily_demand) +
  geom_line(aes(x=daily_demand$date, y=daily_demand$daily_average))

# Create ts object
ts_daily_demand <- msts(daily_demand$daily_average, 
                           seasonal.periods =c(7,365.25),
                           start=c(2005,01,01))

# **NOTE**: Would be nice to add monthly, but I don't see this used in the M10 code or the link referenced there. I'm guessing probably because months can't be expressed precisely in # of days
## I made monthly data! Though because there are so few years, when you reduce to monthly data there are so few observations which makes me think it is better to model with daily data? Open to your thoughts though!
monthly_demand <- daily_demand%>%
  mutate("month" = month(ymd(date)),
         "year" = year(ymd(date)))%>%
  select(month, year, daily_average)%>%
  group_by(month, year)%>%
  summarize(monthly_average = mean(daily_average))%>%
  mutate("month-year" = paste0(month, year, sep="/"))

ggplot(monthly_demand) +
  geom_line(aes(x=`month-year`, y=monthly_average), group=1)
#There seems to be missing data which is a bit weird, could be because of the way I summarized it?


# Create training and testing data from the full ts object
ts_demand_train <- subset(ts_daily_demand,
                          end = length(ts_daily_demand)-365)

#create a subset for testing purpose
ts_demand_test <- subset(ts_daily_demand,
                         start = length(ts_daily_demand)-365)
ts_demand_test <- subset(ts_demand_test,
                         end = length(ts_demand_test)-1) 
# **NOTE**: also something odd going on here with the dates where we are getting an observation for 1/1/2011

# Decompose 
ts_daily_demand %>% mstl() %>%
  autoplot()

decompose <- data.frame(mstl(ts_daily_demand))
ts_remainder <- ts(decompose$Remainder)

# Plot the time series over time, ACF and PACF
par(mfrow=c(1,3), mar=c(6, 4, 4, 2))
plot(ts_remainder, main="Remainder Time Series", ylab = "Demand")
Acf(ts_remainder,lag.max=40, main="ACF") 
Pacf(ts_remainder,lag.max=40, main="PACF")
  # Looks like an AR process?

```


## Fit Models to your Data

Fit models to your dataset considering the period Jan 1st 2005 to Dec 31st 2009. First, we will consider an ARIMA with Fourier terms to account for multiple seasonalities in our data. For this specification, we assume that there are two sine and cosine terms during the weekly season and two sine and cosine terms during the annual season.  

``` {r ARIMA, echo=TRUE, message=FALSE, warning=FALSE}
# First Model: 
ARIMA_Fourier_fit <- auto.arima(ts_demand_train, 
                             seasonal=FALSE, 
                             lambda=0,
                             xreg=fourier(ts_demand_train, 
                                          K=c(2,2)) # 2 weekly cycles, 2 annual cycles
                             )

#Forecast with ARIMA fit
#also need to specify h for fourier terms
ARIMA_Fourier_forecast <- forecast(ARIMA_Fourier_fit,
                           xreg=fourier(ts_demand_train,
                                        K=c(2,2),
                                        h=365),
                           h=365
                           ) 

#Plot foresting results
autoplot(ARIMA_Fourier_forecast) + ylab("Demand")

#Plot model + all observed data
autoplot(ts_daily_demand) +
  autolayer(ARIMA_Fourier_forecast, series="ARIMA_FOURIER",PI=FALSE) +
  ylab("Demand")

# Plot model and observed data during 2010
plot(ARIMA_Fourier_forecast$mean,
     xlab = "Date",
     ylab = "Demand",
     ylim = c(1000, 10000))
lines(ts_demand_test,
      type = "l",
      col = 4,
      lwd = 2)
legend(2010, 10000, legend=c("Forecasting Results", "Last Year of Data (2010)"),
       col=c("black",4), lwd=3, cex=0.8)

accuracy(ARIMA_Fourier_fit)
```

### Fourier Fit Training Data Interpretation
THE RMSE is 518.61 and the MAPE is 11.16. 

## Modeling Full Data
After using the training dataset, re-running with the full dataset to forecast into 2011:
```{r}
# First Model: 
ARIMA_Fourier_full <- auto.arima(ts_daily_demand, 
                             seasonal=FALSE, 
                             lambda=0,
                             xreg=fourier(ts_daily_demand, 
                                          K=c(2,2)) # 2 weekly cycles, 2 annual cycles
                             )

#Forecast with ARIMA fit
#also need to specify h for fourier terms
ARIMA_Fourier_FULLforecast <- forecast(ARIMA_Fourier_full,
                           xreg=fourier(ts_daily_demand,
                                        K=c(2,2),
                                        h=60),
                           h=60
                           #Set H to 60 because I think we are only forecasting till February. I changed both h values to 60 because when only changing 1 (just the second one not in the xreg parantheses) it still had 365 days of forecasting. 
                           ) 
autoplot(ARIMA_Fourier_FULLforecast) + ylab("Demand")

accuracy(ARIMA_Fourier_full)



```

## Model with Full data: 
RMSE 516 and MAPE 10.9. The Forecast plot seems to show a huge range in demand. 


## Export Model Results
```{r}
ARIMA_fourier_export <- as.data.frame(ARIMA_Fourier_FULLforecast)
write.csv(ARIMA_Fourier_forecast, file="./Submissions/ARIMA_fourier_v1.csv")

```



### TBATS Model 

BATS is Exponential smoothing state space model with **B**ox-Cox transformation, **A**RMA errors, **T**rend and **S**easonal components. TBATS is a trigonometric seasonal variation of BATS. A Box Cox transformation is a transformation of non-normal dependent variables into a normal shape. 

## This looks SUPER weird... 
not sure what's going on! 
```{r TBATS, echo=TRUE, message=FALSE, warning=FALSE}
# TBATS can take time to fit
TBATS_fit <- tbats(ts_demand_train)

TBATS_for <- forecast(TBATS_fit, h=365)

#Plot foresting results
autoplot(TBATS_for) +
  ylab("Active Power") 

#Plot model + observed data
autoplot(ts_demand_train) +
  autolayer(TBATS_for, series="TBATS",PI=FALSE)+
  ylab("Electricity Demand") 

accuracy(TBATS_for)
```

### TBATS Interpretation
Unsurprisingly, this model did not perform well. the MAPE was 40.04 -- much much higher than the other models. 

### STL + ETS
```{r}
#Fit and forecast STL + ETS model to data
ETS_fit <-  stlf(ts_demand_train,h=365)

#Plot foresting results
autoplot(ETS_fit) + ylab("Active Power")

#Plot model + observed data
autoplot(ts_demand_train) +
  autolayer(ETS_fit, series="STL + ETS",PI=FALSE) +
  ylab("Active Power")

accuracy(ETS_fit)
```

### STL + ETS Interpretation 
The RMSE is 442.2992 and the MAPE is 9.67, both lower than the original ARIMA_Fourier.  

## Full Data Modeling
```{r}
#Fit and forecast STL + ETS model to data
ETS_fit_full <-  stlf(ts_daily_demand,h=365)

#Plot foresting results
autoplot(ETS_fit) + ylab("Active Power")

#Plot model + observed data
autoplot(ts_daily_demand) +
  autolayer(ETS_fit_full, series="STL + ETS",PI=FALSE) +
  ylab("Active Power")

accuracy(ETS_fit_full)
```
## Full Dataset Accuracy
MAPE: 9.59, RMSE 450.54

## Export Model Results
```{r}
ETS_STL_export <- as.data.frame(ETS_fit_full)
write.csv(ETS_STL_export, file="./Submissions/ETS_STL_v1.csv")

```


## Saving Code
I saw this pasted from the in-class exercise -- I didn't want to delete it all together so I just put it down here to streamline

```{r ARIMA, echo=TRUE, message=FALSE, warning=FALSE}
#Fit arima model with fourier terms as exogenous regressors
# seasonal = FALSE is the same as P=D=Q=0
# play with K by changing it to K=c(2,2), K=c(2,4), K=c(2,6), etc. The higher teh K the longer it will take to converge, because R will try more models.


ARIMA_Fourier_fit <- auto.arima(ts_demand_train, 
                             seasonal=FALSE, 
                             lambda=0,
                             xreg=fourier(ts_demand_train, 
                                          K=c(2,2)) # 2 weekly cycles, 2 annual cycles
                             )

ARIMA_Four_fit <- auto.arima(ts_act_power_daily_train, 
                             seasonal=FALSE, 
                             lambda=0,
                             xreg=fourier(ts_act_power_daily_train, 
                                          K=c(2,12))
                             )

#Forecast with ARIMA fit
#also need to specify h for fourier terms
ARIMA_Four_for <- forecast(ARIMA_Four_fit,
                           xreg=fourier(ts_act_power_daily_train,
                                        K=c(2,12),
                                        h=365),
                           h=365
                           ) 

#Plot foresting results
autoplot(ARIMA_Four_for) + ylab("Active Power")

#Plot model + observed data
autoplot(ts_act_power_daily) +
  autolayer(ARIMA_Four_for, series="ARIMA_FOURIER",PI=FALSE) +
  ylab("Active Power")

```

